{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.svm as svm\n",
    "import sklearn.metrics as mt\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data= pd.read_csv(\"C:/Users/19lya/Documents/Python/Data/ML TeamProj/master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiniData=pd.read_csv(\"C:/Users/19lya/Documents/Python/Data/ML TeamProj/master_mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniData.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 변수 제거 후 X데이터,Y데이터로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz= list(Data.columns)\n",
    "\n",
    "lz.remove('outcome_critical')\n",
    "lz.remove('intime')\n",
    "lz.remove('outtime')\n",
    "lz.remove('ed_los')\n",
    "lz.remove('outcome_icu_transfer_12h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Data[lz]\n",
    "Y= Data[['outcome_critical']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz= list(MiniData.columns)\n",
    "\n",
    "lz.remove('outcome_critical')\n",
    "lz.remove('intime')\n",
    "lz.remove('outtime')\n",
    "lz.remove('ed_los')\n",
    "lz.remove('outcome_icu_transfer_12h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mini= MiniData[lz]\n",
    "Y_mini= MiniData[['outcome_critical']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training데이터, Test데이터로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imbalanced classification-> SMOTE\n",
    "sm = SMOTE(random_state=0)\n",
    "X_smote, Y_smote = sm.fit_sample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0) \n",
    "X_smote_mini, Y_smote_mini = sm.fit_sample(X_mini, Y_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(X_smote, Y_smote, test_size= 0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mini, X_test_mini, Y_train_mini, Y_test_mini= train_test_split(X_smote_mini, Y_smote_mini, test_size= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629080, 96)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209694, 96)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6318, 98)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2106, 98)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mini.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SVM 모델 생성, 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. linear kernel SVM -> Too high time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf= svm.SVC(kernel= 'linear')\n",
    "# clf.fit(X_train, Y_train)\n",
    "# Y_pred= clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. rbf kernel SVM -> Too high time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf2= svm.SVC(kernel= 'rbf', C= 8, gamma= .1) \n",
    "# #C: 정규화비용(크면 좁은 margin, 작으면 넓은 margin)\n",
    "# #gamma: 보통 1/sigma^2, 크면 예민한db, 작으면 smooth한db\n",
    "\n",
    "# clf2.fit(X_train, Y_train)\n",
    "# Y_pred2= clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SGDClassifier 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19lya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\19lya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "sgdClf= SGDClassifier(loss='hinge', learning_rate= 'optimal', epsilon= .05, alpha= .01, random_state= 2001)\n",
    "sgdClf.fit(X_train, Y_train)\n",
    "Y_pred3= sgdClf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 확률적 경사하강법으로 최적화할 손실함수 지정 <br/>\n",
    "penalty: 규제 종류 지정 (기본: 'l2') <br/>\n",
    "alpha: 규제 강도 <br/>\n",
    "max_iter: 에포크 횟수 <br/>\n",
    "tol: 반복 멈출 조건 (기본: .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19lya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "sgdClf_mini= SGDClassifier(loss='hinge', learning_rate= 'optimal', epsilon= .05, alpha= .01, random_state= 2001)\n",
    "sgdClf_mini.fit(X_train_mini, Y_train_mini)\n",
    "Y_pred_mini= sgdClf_mini.predict(X_test_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy: \", mt.accuracy_score(Y_test, Y_pred))\n",
    "# print(\"Precision: \", mt.precision_score(Y_test, Y_pred))\n",
    "# print(\"Recall: \", mt.recall_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy: \", mt.accuracy_score(Y_test, Y_pred2))\n",
    "# print(\"Precision: \", mt.precision_score(Y_test, Y_pred2))\n",
    "# print(\"Recall: \", mt.recall_score(Y_test, Y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49943727526777115\n",
      "Precision:  0.4994372752677712\n",
      "Recall:  1.0\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.00      0.00    104965\n",
      "        True       0.50      1.00      0.67    104729\n",
      "\n",
      "    accuracy                           0.50    209694\n",
      "   macro avg       0.75      0.50      0.33    209694\n",
      "weighted avg       0.75      0.50      0.33    209694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", mt.accuracy_score(Y_test, Y_pred3))\n",
    "print(\"Precision: \", mt.precision_score(Y_test, Y_pred3, average='weighted', labels=np.unique(Y_pred3)))\n",
    "print(\"Recall: \", mt.recall_score(Y_test, Y_pred3, average='weighted', labels=np.unique(Y_pred3)))\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred3, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49477682811016144\n",
      "Precision:  0.7500272815245907\n",
      "Recall:  0.49477682811016144\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.49      1.00      0.66      1042\n",
      "        True       1.00      0.00      0.00      1064\n",
      "\n",
      "    accuracy                           0.49      2106\n",
      "   macro avg       0.75      0.50      0.33      2106\n",
      "weighted avg       0.75      0.49      0.33      2106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", mt.accuracy_score(Y_test_mini, Y_pred_mini))\n",
    "print(\"Precision: \", mt.precision_score(Y_test_mini, Y_pred_mini, zero_division=1, average='weighted'))\n",
    "print(\"Recall: \", mt.recall_score(Y_test_mini, Y_pred_mini,zero_division=1, average='weighted'))\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(classification_report(Y_test_mini, Y_pred_mini, zero_division= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 하이퍼파리미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel: The main function of the kernel is to transform the given dataset input data into the required form. There are various types of functions such as linear, polynomial, and radial basis function (RBF). Polynomial and RBF are useful for non-linear hyperplane. Polynomial and RBF kernels compute the separation line in the higher dimension. In some of the applications, it is suggested to use a more complex kernel to separate the classes that are curved or nonlinear. This transformation can lead to more accurate classifiers.\n",
    "\n",
    "Regularization: Regularization parameter in python's Scikit-learn C parameter used to maintain regularization. Here C is the penalty parameter, which represents misclassification or error term. The misclassification or error term tells the SVM optimization how much error is bearable. This is how you can control the trade-off between decision boundary and misclassification term. A smaller value of C creates a small-margin hyperplane and a larger value of C creates a larger-margin hyperplane.\n",
    "\n",
    "Gamma: A lower value of Gamma will loosely fit the training dataset, whereas a higher value of gamma will exactly fit the training dataset, which causes over-fitting. In other words, you can say a low value of gamma considers only nearby points in calculating the separation line, while the a value of gamma considers all the data points in the calculation of the separation line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgdClf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters = {'alpha': (1e-2, 1e-3)}\n",
    " \n",
    "# sgdClf_gs = GridSearchCV(sgdClf, parameters)\n",
    "# sgdClf_gs.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_predGS= sgdClf_gs.predict(X_test)\n",
    "# print(classification_report(Y_test, Y_predGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'alpha': (1e-2, 1e-3)}\n",
    "\n",
    "# sgdClf_gs_mini = GridSearchCV(sgdClf_mini, parameters)\n",
    "# sgdClf_gs_mini.fit(X_train_mini, Y_train_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_predGS_mini= sgdClf_gs_mini.predict(X_test_mini)\n",
    "# print(classification_report(Y_test_mini, Y_predGS_mini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplot_decision_regions(X_combined_std, \\n                      y_combined,\\n                      classifier=svm, \\n                      test_idx=range(105, 150))\\nplt.scatter(svm.dual_coef_[0, :], svm.dual_coef_[1, :])\\nplt.xlabel('petal length [standardized]')\\nplt.ylabel('petal width [standardized]')\\nplt.legend(loc='upper left')\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#변수 개수 2개로 줄여야 graph에 시각화 가능\n",
    "'''\n",
    "plot_decision_regions(X_combined_std, \n",
    "                      y_combined,\n",
    "                      classifier=svm, \n",
    "                      test_idx=range(105, 150))\n",
    "plt.scatter(svm.dual_coef_[0, :], svm.dual_coef_[1, :])\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
